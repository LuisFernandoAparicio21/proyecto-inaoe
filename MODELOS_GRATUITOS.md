# ü§ñ Modelos LLM Gratuitos para tu Proyecto RAG

## üÜì Modelos Completamente Gratuitos

### 1. **Ollama (Local) - Recomendado para uso intensivo**

#### Instalaci√≥n:
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Iniciar Ollama
ollama serve

# Descargar modelos (en otra terminal)
ollama pull llama3.2:1b
ollama pull llama3.2:3b
ollama pull qwen2.5:3b
ollama pull phi3:mini
ollama pull gemma2:2b
ollama pull mistral:7b
```

#### Modelos Recomendados:
- **llama3.2:1b** - ‚ö° Muy r√°pido, 1GB RAM, bueno para tareas simples
- **llama3.2:3b** - ‚ö° R√°pido, 2GB RAM, mejor calidad
- **qwen2.5:3b** - üåç Excelente para espa√±ol, 2GB RAM
- **phi3:mini** - ‚ö° Muy eficiente, 1.5GB RAM
- **gemma2:2b** - üîç De Google, bueno para tareas espec√≠ficas
- **mistral:7b** - üß† Excelente calidad, 4GB RAM

### 2. **Google Gemini API - Gratis con l√≠mites**

#### Configuraci√≥n:
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crea una API key gratuita
3. A√±ade a `.streamlit/secrets.toml`:
```toml
GOOGLE_API_KEY = "tu-api-key-aqui"
```

#### L√≠mites Gratuitos:
- **15 requests por minuto**
- **1,500 requests por d√≠a**
- Modelos disponibles: `gemini-1.5-flash`, `gemini-1.5-pro`

### 3. **Hugging Face Inference API - 30,000 requests/mes gratis**

#### Configuraci√≥n:
1. Ve a [Hugging Face](https://huggingface.co/settings/tokens)
2. Crea un token de acceso
3. A√±ade a `.streamlit/secrets.toml`:
```toml
HUGGINGFACE_API_KEY = "tu-token-aqui"
```

#### Modelos Recomendados:
- `microsoft/DialoGPT-medium` - Chat en espa√±ol
- `microsoft/DialoGPT-large` - Chat avanzado
- `gpt2` - Texto en ingl√©s
- `facebook/opt-350m` - Texto multiling√ºe

### 4. **Together AI - $25 cr√©ditos gratis mensuales**

#### Configuraci√≥n:
1. Ve a [Together AI](https://together.ai/)
2. Reg√≠strate y obt√©n $25 cr√©ditos gratis
3. Crea una API key
4. A√±ade a `.streamlit/secrets.toml`:
```toml
TOGETHER_API_KEY = "tu-api-key-aqui"
```

#### Modelos Recomendados:
- `togethercomputer/llama-2-7b-chat` - Chat de alta calidad
- `togethercomputer/llama-2-13b-chat` - Chat avanzado
- `togethercomputer/falcon-7b-instruct` - Instrucciones
- `togethercomputer/redpajama-incite-7b-instruct` - Instrucciones

## üìä Comparaci√≥n de Modelos

| Modelo | Tipo | Velocidad | Calidad | RAM | Gratis |
|--------|------|-----------|---------|-----|--------|
| llama3.2:1b | Local | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | 1GB | ‚úÖ |
| llama3.2:3b | Local | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 2GB | ‚úÖ |
| qwen2.5:3b | Local | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 2GB | ‚úÖ |
| mistral:7b | Local | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 4GB | ‚úÖ |
| gemini-1.5-flash | API | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | - | ‚úÖ* |
| Together AI | API | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | - | ‚úÖ** |

*15 req/min gratis
**$25 cr√©ditos/mes gratis

## üöÄ Configuraci√≥n R√°pida

### Para Ollama (Recomendado):
```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Iniciar servicio
ollama serve

# 3. Descargar modelo recomendado
ollama pull llama3.2:3b

# 4. Probar
ollama run llama3.2:3b "Hola, ¬øc√≥mo est√°s?"
```

### Para APIs:
1. Crea las API keys mencionadas arriba
2. A√±√°delas a `.streamlit/secrets.toml`
3. Instala dependencias adicionales:
```bash
pip install langchain-groq langchain-together
```

## üí° Recomendaciones por Caso de Uso

### Para Investigaci√≥n Acad√©mica:
- **llama3.2:3b** (local) - Buen balance
- **mistral:7b** (local) - Mejor calidad
- **gemini-1.5-flash** (API) - Excelente para an√°lisis

### Para Chat en Espa√±ol:
- **qwen2.5:3b** (local) - Especializado en espa√±ol
- **llama3.2:3b** (local) - Bueno en espa√±ol

### Para Uso Intensivo:
- **llama3.2:1b** (local) - Muy r√°pido
- **phi3:mini** (local) - Muy eficiente

### Para M√°xima Calidad:
- **mistral:7b** (local) - Excelente calidad
- **gemini-1.5-flash** (API) - Muy preciso

## üîß Soluci√≥n de Problemas

### Ollama no responde:
```bash
# Reiniciar servicio
ollama serve

# Verificar modelos instalados
ollama list

# Reinstalar modelo
ollama rm llama3.2:3b
ollama pull llama3.2:3b
```

### Error de memoria:
- Usa modelos m√°s peque√±os (1b o 2b)
- Cierra otras aplicaciones
- Aumenta la memoria virtual

### Error de API:
- Verifica que las API keys est√©n correctas
- Revisa los l√≠mites de uso
- Prueba con otro modelo

## üìà Monitoreo de Uso

### Ollama:
```bash
# Ver uso de memoria
ollama ps

# Ver logs
ollama logs
```

### APIs:
- Google Gemini: [Google AI Studio](https://makersuite.google.com/app/apikey)
- Hugging Face: [Settings](https://huggingface.co/settings/tokens)
- Together AI: [Dashboard](https://together.ai/dashboard)

¬°Con estos modelos tendr√°s acceso a LLMs de alta calidad sin costo! üéâ

